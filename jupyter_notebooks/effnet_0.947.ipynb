{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor\n",
    "import albumentations as alb\n",
    "\n",
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, n_classes, pretrained_backbone, mixed_precision, model_name='tf_efficientnet_b7_ns'):\n",
    "        super().__init__()\n",
    "        self.amp = mixed_precision\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained_backbone)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(n_features, 11)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.amp:\n",
    "            with autocast():\n",
    "                bs = x.size(0)\n",
    "                features = self.model(x)\n",
    "                pooled_features = self.pooling(features).view(bs, -1)\n",
    "                x = self.classifier(pooled_features)\n",
    "        else:\n",
    "            bs = x.size(0)\n",
    "            features = self.model(x)\n",
    "            pooled_features = self.pooling(features).view(bs, -1)\n",
    "            x = self.classifier(pooled_features)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EfficientNet(11, pretrained_backbone=False, mixed_precision=True, model_name='tf_efficientnet_b7_ns')\n",
    "\n",
    "state_dict = torch.load('../input/effnet7-epoch14-val-auc-0947-loss-0455/model_epoch_14_val_auc_0.947_loss_0.455_train_auc_0.951_loss_0.34.pth')\n",
    "# create new OrderedDict that does not contain `module.`\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self, transform, dataset_filepath, image_h_w_ratio=0.8192, width_size=128):\n",
    "        self.files = [filepath for filepath in glob.iglob(os.path.join(dataset_filepath, '*'))]\n",
    "        self.transform = transform\n",
    "        self.dataset_filepath = dataset_filepath\n",
    "        self.image_h_w_ratio = image_h_w_ratio\n",
    "        self.width_size = width_size\n",
    "        self.height_size = int(self.image_h_w_ratio * self.width_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.files[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "\n",
    "        image_h, image_w = image.shape[0], image.shape[1]\n",
    "        if image_h / image_w > self.image_h_w_ratio:\n",
    "            ratio_coeff = self.height_size / image_h\n",
    "        else:\n",
    "            ratio_coeff = self.width_size / image_w\n",
    "        new_h = int(image_h * ratio_coeff)\n",
    "        new_w = int(image_w * ratio_coeff)\n",
    "        image = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "        w_padding = (self.width_size - new_w) / 2\n",
    "        h_padding = (self.height_size - new_h) / 2\n",
    "        l_padding = int(w_padding)\n",
    "        t_padding = int(h_padding)\n",
    "        r_padding = int(new_w + (w_padding if w_padding % 1 == 0 else w_padding - 0.5))\n",
    "        b_padding = int(new_h + (h_padding if h_padding % 1 == 0 else h_padding - 0.5))\n",
    "\n",
    "        result_image = np.full((self.height_size, self.width_size, 3), 0, dtype=np.uint8)\n",
    "        result_image[t_padding:b_padding, l_padding:r_padding, :] = image\n",
    "        result_image = np.reshape(result_image, (result_image.shape[0], result_image.shape[1], 3))\n",
    "\n",
    "        if self.transform:\n",
    "            result_image = self.transform(image=result_image)\n",
    "\n",
    "        return image_filepath.rsplit('/', 1)[1].rsplit('.', 1)[0], result_image['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = alb.Compose([\n",
    "    alb.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "test_set = ImageDataset(image_transforms, '../input/ranzcr-clip-catheter-line-classification/test', width_size=640)\n",
    "test_loader = DataLoader(test_set, batch_size=64, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "filepaths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        filepaths_batch, image_batch = batch\n",
    "        prediction_batch = model(image_batch.to(device))\n",
    "\n",
    "        predictions.extend(prediction_batch.cpu().numpy())\n",
    "        filepaths.extend(filepaths_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)\n",
    "df = pd.DataFrame({\n",
    "    'StudyInstanceUID': filepaths,\n",
    "    'ETT - Abnormal': predictions[:, 0],\n",
    "    'ETT - Borderline': predictions[:, 1],\n",
    "    'ETT - Normal': predictions[:, 2],\n",
    "    'NGT - Abnormal': predictions[:, 3],\n",
    "    'NGT - Borderline': predictions[:, 4],\n",
    "    'NGT - Incompletely Imaged': predictions[:, 5],\n",
    "    'NGT - Normal': predictions[:, 6],\n",
    "    'CVC - Abnormal': predictions[:, 7],\n",
    "    'CVC - Borderline': predictions[:, 8],\n",
    "    'CVC - Normal': predictions[:, 9],\n",
    "    'Swan Ganz Catheter Present': predictions[:, 10]})\n",
    "df.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
